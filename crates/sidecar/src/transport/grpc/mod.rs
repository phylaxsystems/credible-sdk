//! # `gRPC` transport
//!
//! The following is a transport implementation for gRPC/Protobuf for the sidecar.
//!
//! We use `prost` to generate protobuf rust code from a protobuf definition, and create a
//! `tonic` service from it.
//!
//! We implement the `Transport` trait here that binds the `tonic` service,
//! with the above mentioned generated definitions, inside of `run()`
//! and run the grpc server on the same address we would any other transport.
//!
//! ## Streaming Architecture
//! - `StreamEvents`: Bidirectional stream replacing `SendEvents`, `SendTransactions`, `Reorg`
//! - `SubscribeResults`: Server stream pushing transaction results as they complete
//!
//! The result streaming works as follows:
//! 1. `TransactionsState` sends results via a flume channel (transport-agnostic)
//! 2. `GrpcService` spawns a task consuming from the flume channel
//! 3. Results are broadcast to all gRPC `SubscribeResults` subscribers
//!
//! ## Metrics
//! The grpc transport exposes the following metrics:
//! - `sidecar_rpc_duration_GetTransactions`
//! - `sidecar_rpc_duration_GetTransaction`
//! - `sidecar_fetch_transaction_result_duration`
//!
//! ## Type definitions
//! Protobuf typing can be found below:
//!
//! ```protobuf
#![doc = include_str!("./sidecar.proto")]
//! ```

#![allow(clippy::large_enum_variant)]
#![allow(clippy::trivially_copy_pass_by_ref)]
use crate::{
    engine::queue::TransactionQueueSender,
    transactions_state::{
        TransactionResultEvent,
        TransactionsState,
    },
    transport::{
        Transport,
        transactions_results::QueryTransactionsResults,
    },
    utils::ErrorRecoverability,
};
use std::{
    net::SocketAddr,
    sync::Arc,
    time::Duration,
};
use tokio_util::sync::CancellationToken;
use tracing::{
    debug,
    error,
    info,
    instrument,
};

pub mod config;
mod server;

pub use server::{
    GrpcDecodeError,
    GrpcService,
    convert_pb_tx_env_to_revm,
    decode_transaction,
    decode_tx_env,
    to_queue_tx,
};

pub const TCP_KEEPALIVE: Duration = Duration::from_secs(60);
pub const HTTP2_KEEPALIVE_INTERVAL: Duration = Duration::from_secs(30);
pub const HTTP2_KEEPALIVE_TIMEOUT: Duration = Duration::from_secs(90);
pub const MAX_CONCURRENT_CONNECTIONS: u32 = 1000;
pub const INITIAL_STREAM_WINDOW: u32 = 2 * 1024 * 1024; // 2MB
pub const INITIAL_CONNECTION_WINDOW: u32 = 16 * 1024 * 1024; // 16MB
pub const MAX_FRAME_SIZE: u32 = 32768; // 32KB

// Generated by build.rs from sidecar.proto
// The generated code path is implicit via tonic::include_proto. We wrap it into a module here
// to keep the public surface small and avoid exposing prost types outside this module.
#[allow(dead_code)]
mod pb_inner {
    tonic::include_proto!("sidecar.transport.v1");
}

#[cfg(test)]
pub mod pb {
    pub use super::pb_inner::*;
}

#[cfg(not(test))]
pub mod pb {
    pub use super::pb_inner::*;
}

#[derive(thiserror::Error, Debug)]
pub enum GrpcTransportError {
    #[error("Server error: {0}")]
    ServerError(String),
    #[error("Failed to bind the address: {0}")]
    BindAddress(String),
    #[error("Client error: {0}")]
    ClientError(String),
}

impl From<&GrpcTransportError> for ErrorRecoverability {
    fn from(e: &GrpcTransportError) -> Self {
        match e {
            GrpcTransportError::ServerError(_) | GrpcTransportError::BindAddress(_) => {
                Self::Unrecoverable
            }
            GrpcTransportError::ClientError(_) => Self::Recoverable,
        }
    }
}

/// Skeleton implementation of a gRPC `Transport`.
#[derive(Debug)]
pub struct GrpcTransport {
    /// Core engine queue sender.
    tx_sender: TransactionQueueSender,
    /// Server bind address
    bind_addr: SocketAddr,
    /// Shutdown cancellation token
    shutdown_token: CancellationToken,
    /// Shared transaction results state
    transactions_results: QueryTransactionsResults,
    /// Receiver for transaction result events from the engine.
    /// This allows streaming results to gRPC subscribers.
    result_event_rx: Option<flume::Receiver<TransactionResultEvent>>,
    /// Event ID deduplication buffer capacity.
    event_id_buffer_capacity: usize,
}

impl Transport for GrpcTransport {
    type Error = GrpcTransportError;
    type Config = config::GrpcTransportConfig;

    #[instrument(name = "grpc_transport::new", skip_all, level = "debug")]
    fn new(
        config: Self::Config,
        tx_sender: TransactionQueueSender,
        state_results: Arc<TransactionsState>,
    ) -> Result<Self, Self::Error> {
        let bind_addr = config
            .bind_socket_addr()
            .map_err(|e| GrpcTransportError::BindAddress(e.to_string()))?;
        debug!(bind_addr = %config.bind_addr, "Creating gRPC transport");
        Ok(Self {
            tx_sender,
            bind_addr,
            shutdown_token: CancellationToken::new(),
            transactions_results: QueryTransactionsResults::new(
                state_results,
                config.pending_receive_ttl,
            ),
            result_event_rx: None,
            event_id_buffer_capacity: config.event_id_buffer_capacity,
        })
    }

    #[instrument(
        name = "grpc_transport::run",
        skip(self),
        fields(bind_addr = %self.bind_addr),
        level = "info"
    )]
    async fn run(&self) -> Result<(), Self::Error> {
        use tonic::transport::Server;

        let service = server::GrpcService::new(
            self.tx_sender.clone(),
            self.transactions_results.clone(),
            self.result_event_rx.clone(),
            self.event_id_buffer_capacity,
        );

        info!(bind_addr = %self.bind_addr, "gRPC transport server starting");

        let shutdown = self.shutdown_token.clone();
        Server::builder()
            .tcp_nodelay(true)
            .tcp_keepalive(Some(TCP_KEEPALIVE))
            .http2_keepalive_interval(Some(HTTP2_KEEPALIVE_INTERVAL))
            .http2_keepalive_timeout(Some(HTTP2_KEEPALIVE_TIMEOUT))
            .http2_adaptive_window(Some(true))
            .max_concurrent_streams(Some(MAX_CONCURRENT_CONNECTIONS))
            .initial_stream_window_size(Some(INITIAL_STREAM_WINDOW))
            .initial_connection_window_size(Some(INITIAL_CONNECTION_WINDOW))
            .max_frame_size(Some(MAX_FRAME_SIZE))
            .add_service(pb::sidecar_transport_server::SidecarTransportServer::new(
                service,
            ))
            .serve_with_shutdown(self.bind_addr, async move { shutdown.cancelled().await })
            .await
            .map_err(|e| {
                error!(error = ?e, "gRPC server failed");
                GrpcTransportError::ServerError(e.to_string())
            })?;

        Ok(())
    }

    #[instrument(name = "grpc_transport::stop", skip(self), level = "info")]
    fn stop(&mut self) {
        info!("Stopping gRPC transport");
        self.shutdown_token.cancel();
    }
}

impl GrpcTransport {
    /// Create a new GrpcTransport with a result event receiver.
    pub fn with_result_receiver(
        config: &config::GrpcTransportConfig,
        tx_sender: TransactionQueueSender,
        state_results: Arc<TransactionsState>,
        result_event_rx: flume::Receiver<TransactionResultEvent>,
    ) -> Result<Self, GrpcTransportError> {
        debug!(bind_addr = %config.bind_addr, "Creating streaming gRPC transport with result receiver");
        let bind_addr = config
            .bind_socket_addr()
            .map_err(|e| GrpcTransportError::BindAddress(e.to_string()))?;
        Ok(Self {
            tx_sender,
            bind_addr,
            shutdown_token: CancellationToken::new(),
            transactions_results: QueryTransactionsResults::new(
                state_results,
                config.pending_receive_ttl,
            ),
            result_event_rx: Some(result_event_rx),
            event_id_buffer_capacity: config.event_id_buffer_capacity,
        })
    }
}

#[cfg(test)]
mod tests {
    #![allow(clippy::cast_sign_loss)]
    #![allow(clippy::expect_fun_call)]
    #![allow(clippy::cast_possible_truncation)]

    use super::pb::{
        self,
        Event,
        GetTransactionRequest,
        SubscribeResultsRequest,
        TxExecutionId,
        event::Event as EventVariant,
        get_transaction_response::Outcome as GetTransactionOutcome,
        sidecar_transport_client::SidecarTransportClient,
    };
    use crate::transport::event_id_deduplication::EventIdBuffer;
    use alloy::primitives::B256;
    use assertion_executor::primitives::{
        Bytes,
        U256,
    };
    use futures::StreamExt;
    use std::{
        net::SocketAddr,
        time::Duration,
    };
    use tokio_stream::wrappers::ReceiverStream;
    use tonic::transport::Channel;

    /// Delay used in tests to wait for async operations to complete.
    const TEST_WAIT_DELAY: Duration = Duration::from_millis(50);

    // Helper functions for binary encoding in tests
    fn encode_b256(hash: B256) -> Vec<u8> {
        hash.as_slice().to_vec()
    }

    fn encode_u256_be(val: U256) -> Vec<u8> {
        val.to_be_bytes::<32>().to_vec()
    }

    #[allow(dead_code)]
    fn encode_u128_be(val: u128) -> Vec<u8> {
        val.to_be_bytes().to_vec()
    }

    #[crate::utils::engine_test(grpc)]
    async fn test_get_transaction_returns_successful_result(
        mut instance: crate::utils::LocalInstance,
    ) {
        let tx_execution_id = instance
            .send_successful_create_tx(U256::from(0u64), Bytes::new())
            .await
            .expect("failed to send transaction");

        assert!(
            instance
                .is_transaction_successful(&tx_execution_id)
                .await
                .expect("transaction query failed"),
            "transaction expected to succeed"
        );

        let address = instance
            .local_address
            .expect("grpc transport should expose an address");

        let mut client = SidecarTransportClient::connect(format!("http://{address}"))
            .await
            .expect("failed to connect grpc client");

        let response = client
            .get_transaction(GetTransactionRequest {
                tx_execution_id: Some(TxExecutionId {
                    block_number: tx_execution_id.block_number.to_be_bytes::<32>().to_vec(),
                    iteration_id: tx_execution_id.iteration_id,
                    tx_hash: encode_b256(tx_execution_id.tx_hash),
                    index: tx_execution_id.index,
                }),
            })
            .await
            .expect("get_transaction RPC failed")
            .into_inner();

        match response.outcome {
            Some(GetTransactionOutcome::Result(result)) => {
                let hash_bytes = result
                    .tx_execution_id
                    .expect("missing tx_execution_id")
                    .tx_hash;
                assert_eq!(hash_bytes.len(), 32, "hash should be 32 bytes");
                let parsed_hash = B256::from_slice(&hash_bytes);
                assert_eq!(
                    parsed_hash, tx_execution_id.tx_hash,
                    "queried hash should match"
                );
                assert_eq!(result.status, pb::ResultStatus::Success as i32);
                assert!(result.gas_used > 0, "gas_used expected to be populated");
                assert!(
                    result.error.is_empty(),
                    "error should be empty for successful transactions"
                );
            }
            other => panic!("unexpected outcome: {other:?}"),
        }
    }

    #[crate::utils::engine_test(grpc)]
    async fn test_get_transaction_reports_not_found(mut instance: crate::utils::LocalInstance) {
        instance
            .new_block()
            .await
            .expect("failed to announce new block");
        instance
            .wait_for_processing(Duration::from_millis(10))
            .await;

        let missing_hash = B256::repeat_byte(0x24);
        let address = instance
            .local_address
            .expect("grpc transport should expose an address");

        let mut client = SidecarTransportClient::connect(format!("http://{address}"))
            .await
            .expect("failed to connect grpc client");

        let response = client
            .get_transaction(GetTransactionRequest {
                tx_execution_id: Some(TxExecutionId {
                    block_number: U256::ZERO.to_be_bytes::<32>().to_vec(),
                    iteration_id: 1,
                    tx_hash: encode_b256(missing_hash),
                    index: 0,
                }),
            })
            .await
            .expect("get_transaction RPC failed")
            .into_inner();

        match response.outcome {
            Some(GetTransactionOutcome::NotFound(hash_bytes)) => {
                assert_eq!(hash_bytes.len(), 32, "hash should be 32 bytes");
                let parsed = B256::from_slice(&hash_bytes);
                assert_eq!(parsed, missing_hash);
            }
            other => panic!("unexpected outcome: {other:?}"),
        }
    }

    #[crate::utils::engine_test(grpc)]
    async fn test_stream_single_transaction_success(mut instance: crate::utils::LocalInstance) {
        let tx_execution_id = instance
            .send_successful_create_tx(U256::from(0u64), Bytes::new())
            .await
            .expect("failed to send transaction via stream");

        let is_successful = instance
            .is_transaction_successful(&tx_execution_id)
            .await
            .expect("failed to query transaction result");

        assert!(is_successful, "transaction should succeed");
    }

    #[crate::utils::engine_test(grpc)]
    async fn test_stream_multiple_transactions_sequential(
        mut instance: crate::utils::LocalInstance,
    ) {
        let mut tx_ids = Vec::new();

        // Send 5 transactions sequentially
        for i in 0..5 {
            let tx_execution_id = instance
                .send_successful_create_tx(U256::from(i as u64), Bytes::new())
                .await
                .unwrap_or_else(|_| panic!("failed to send transaction {i} via stream"));
            tx_ids.push(tx_execution_id);
        }

        // Verify all transactions succeeded
        for (i, tx_id) in tx_ids.iter().enumerate() {
            let is_successful = instance
                .is_transaction_successful(tx_id)
                .await
                .expect(&format!("failed to query transaction {i} result"));
            assert!(is_successful, "transaction {i} should succeed");
        }
    }

    /// Connect to gRPC server with retries for test reliability.
    async fn connect_grpc_client_with_retry(
        address: SocketAddr,
    ) -> SidecarTransportClient<Channel> {
        const MAX_ATTEMPTS: usize = 10;
        const RETRY_DELAY: Duration = Duration::from_millis(50);

        for attempt in 1..=MAX_ATTEMPTS {
            match SidecarTransportClient::connect(format!("http://{address}")).await {
                Ok(client) => return client,
                Err(e) if attempt == MAX_ATTEMPTS => {
                    panic!("Failed to connect to gRPC server after {MAX_ATTEMPTS} attempts: {e}");
                }
                Err(_) => {
                    tokio::time::sleep(RETRY_DELAY).await;
                }
            }
        }
        unreachable!()
    }

    #[crate::utils::engine_test(grpc)]
    async fn test_subscribe_results_receives_single_transaction(
        mut instance: crate::utils::LocalInstance,
    ) {
        // First announce a block so commit_head_seen is true
        instance
            .new_block()
            .await
            .expect("failed to announce new block");

        // Wait for commit head to be processed before sending events
        // This prevents race conditions when running tests in parallel
        tokio::time::sleep(TEST_WAIT_DELAY).await;

        let address = instance
            .local_address
            .expect("grpc transport should expose an address");

        let mut client = connect_grpc_client_with_retry(address).await;

        // Subscribe to the results stream
        let mut results_stream = client
            .subscribe_results(SubscribeResultsRequest { from_block: None })
            .await
            .expect("subscribe_results failed")
            .into_inner();

        // Now send a transaction
        let tx_execution_id = instance
            .send_successful_create_tx(U256::from(42u64), Bytes::new())
            .await
            .expect("failed to send transaction");

        // Wait for the result on the stream
        let result = tokio::time::timeout(Duration::from_secs(5), results_stream.next())
            .await
            .expect("timeout waiting for result on subscribe stream")
            .expect("stream ended unexpectedly")
            .expect("result error");

        let result_tx_id = result.tx_execution_id.expect("missing tx_execution_id");
        let result_hash = B256::from_slice(&result_tx_id.tx_hash);

        assert_eq!(
            result_hash, tx_execution_id.tx_hash,
            "received hash should match sent tx"
        );
        assert_eq!(result.status, pb::ResultStatus::Success as i32);
        assert!(result.gas_used > 0, "gas_used should be populated");
    }

    #[crate::utils::engine_test(grpc)]
    async fn test_subscribe_results_receives_multiple_transactions(
        mut instance: crate::utils::LocalInstance,
    ) {
        instance
            .new_block()
            .await
            .expect("failed to announce new block");

        // Wait for commit head to be processed before sending events
        // This prevents race conditions when running tests in parallel
        tokio::time::sleep(TEST_WAIT_DELAY).await;

        let address = instance
            .local_address
            .expect("grpc transport should expose an address");

        let mut client = connect_grpc_client_with_retry(address).await;

        let mut results_stream = client
            .subscribe_results(SubscribeResultsRequest { from_block: None })
            .await
            .expect("subscribe_results failed")
            .into_inner();

        // Send multiple transactions
        let mut sent_tx_ids = Vec::new();
        for i in 0..5 {
            let tx_id = instance
                .send_successful_create_tx(U256::from(i as u64), Bytes::new())
                .await
                .expect(&format!("failed to send transaction {i}"));
            sent_tx_ids.push(tx_id);
        }

        // Collect results from stream
        let mut received_hashes = Vec::new();
        for _ in 0..5 {
            let result = tokio::time::timeout(Duration::from_secs(5), results_stream.next())
                .await
                .expect("timeout waiting for result")
                .expect("stream ended")
                .expect("result error");

            let tx_id = result.tx_execution_id.expect("missing tx_execution_id");
            received_hashes.push(B256::from_slice(&tx_id.tx_hash));
            assert_eq!(result.status, pb::ResultStatus::Success as i32);
        }

        // Verify all sent transactions were received (order may vary due to parallel processing)
        let sent_hashes: Vec<_> = sent_tx_ids.iter().map(|id| id.tx_hash).collect();
        for sent_hash in &sent_hashes {
            assert!(
                received_hashes.contains(sent_hash),
                "sent tx {sent_hash:?} should be in received results",
            );
        }
    }

    #[crate::utils::engine_test(grpc)]
    async fn test_subscribe_results_from_block_filter(mut instance: crate::utils::LocalInstance) {
        // Send transaction in block 1
        instance
            .new_block()
            .await
            .expect("failed to announce block 1");

        let _tx_block_1 = instance
            .send_successful_create_tx(U256::from(1u64), Bytes::new())
            .await
            .expect("failed to send tx in block 1");

        // Wait for it to be processed
        instance
            .wait_for_processing(Duration::from_millis(100))
            .await;

        // Now subscribe with from_block = 2 (should not receive block 1 tx)
        let address = instance
            .local_address
            .expect("grpc transport should expose an address");

        let mut client = connect_grpc_client_with_retry(address).await;

        let mut results_stream = client
            .subscribe_results(SubscribeResultsRequest {
                from_block: Some(U256::from(2).to_be_bytes::<32>().to_vec()),
            })
            .await
            .expect("subscribe_results failed")
            .into_inner();

        // Advance to block 2
        instance
            .new_iteration(0)
            .await
            .expect("failed to start iteration for block 2");

        // Send transaction in block 2
        let tx_block_2 = instance
            .send_successful_create_tx(U256::from(2u64), Bytes::new())
            .await
            .expect("failed to send tx in block 2");

        // Should only receive the block 2 transaction
        let result = tokio::time::timeout(Duration::from_secs(5), results_stream.next())
            .await
            .expect("timeout waiting for result")
            .expect("stream ended")
            .expect("result error");

        let result_tx_id = result.tx_execution_id.expect("missing tx_execution_id");
        let block_number =
            U256::from_be_bytes::<32>(result_tx_id.block_number.as_slice().try_into().unwrap());
        assert!(
            block_number >= U256::from(2),
            "should only receive results from block >= 2, got block {block_number:?}",
        );
    }

    #[crate::utils::engine_test(grpc)]
    async fn test_subscribe_results_multiple_subscribers(
        mut instance: crate::utils::LocalInstance,
    ) {
        instance
            .new_block()
            .await
            .expect("failed to announce new block");

        // Wait for commit head to be processed before sending events
        // This prevents race conditions when running tests in parallel
        tokio::time::sleep(TEST_WAIT_DELAY).await;

        let address = instance
            .local_address
            .expect("grpc transport should expose an address");

        // Create two separate clients and subscriptions
        let mut client1 = connect_grpc_client_with_retry(address).await;
        let mut client2 = connect_grpc_client_with_retry(address).await;

        let mut stream1 = client1
            .subscribe_results(SubscribeResultsRequest { from_block: None })
            .await
            .expect("subscribe_results failed for client 1")
            .into_inner();

        let mut stream2 = client2
            .subscribe_results(SubscribeResultsRequest { from_block: None })
            .await
            .expect("subscribe_results failed for client 2")
            .into_inner();

        // Send a transaction
        let tx_execution_id = instance
            .send_successful_create_tx(U256::from(99u64), Bytes::new())
            .await
            .expect("failed to send transaction");

        // Both streams should receive the result
        let result1 = tokio::time::timeout(Duration::from_secs(5), stream1.next())
            .await
            .expect("timeout on stream1")
            .expect("stream1 ended")
            .expect("stream1 error");

        let result2 = tokio::time::timeout(Duration::from_secs(5), stream2.next())
            .await
            .expect("timeout on stream2")
            .expect("stream2 ended")
            .expect("stream2 error");

        let hash1 = B256::from_slice(&result1.tx_execution_id.unwrap().tx_hash);
        let hash2 = B256::from_slice(&result2.tx_execution_id.unwrap().tx_hash);

        assert_eq!(hash1, tx_execution_id.tx_hash);
        assert_eq!(hash2, tx_execution_id.tx_hash);
        assert_eq!(hash1, hash2, "both subscribers should receive same result");
    }

    #[crate::utils::engine_test(grpc)]
    async fn test_different_event_ids_are_all_processed(mut instance: crate::utils::LocalInstance) {
        instance
            .new_block()
            .await
            .expect("failed to announce new block");

        // Wait for commit head to be processed before sending events
        // This prevents race conditions when running tests in parallel
        tokio::time::sleep(TEST_WAIT_DELAY).await;

        let address = instance
            .local_address
            .expect("grpc transport should expose an address");

        let mut client = connect_grpc_client_with_retry(address).await;

        let (tx, rx) = tokio::sync::mpsc::channel::<Event>(32);
        let request_stream = ReceiverStream::new(rx);

        let mut response_stream = client
            .stream_events(request_stream)
            .await
            .expect("stream_events failed")
            .into_inner();

        // Send 5 events with different event_ids
        for i in 1..=5u64 {
            let tx_hash = B256::repeat_byte(i as u8);
            let event = create_transaction_event(i, tx_hash, 1, 1);
            tx.send(event).await.expect("failed to send event");

            let ack = tokio::time::timeout(Duration::from_secs(5), response_stream.next())
                .await
                .expect("timeout waiting for ACK")
                .expect("stream ended")
                .expect("ACK error");

            assert!(ack.success, "event {i} should succeed");
            assert_eq!(ack.event_id, i);
            assert_eq!(
                ack.events_processed, i,
                "events_processed should be {i} after processing event {i}"
            );
        }
    }

    #[crate::utils::engine_test(grpc)]
    async fn test_interleaved_duplicates_and_new_events(mut instance: crate::utils::LocalInstance) {
        instance
            .new_block()
            .await
            .expect("failed to announce new block");

        // Wait for commit head to be processed before sending events
        // This prevents race conditions when running tests in parallel
        tokio::time::sleep(TEST_WAIT_DELAY).await;

        let address = instance
            .local_address
            .expect("grpc transport should expose an address");

        let mut client = connect_grpc_client_with_retry(address).await;

        let (tx, rx) = tokio::sync::mpsc::channel::<Event>(32);
        let request_stream = ReceiverStream::new(rx);

        let mut response_stream = client
            .stream_events(request_stream)
            .await
            .expect("stream_events failed")
            .into_inner();

        // Send events in pattern: 1, 2, 1 (dup), 3, 2 (dup), 4
        let event_ids = [1u64, 2, 1, 3, 2, 4];
        let expected_processed = [1u64, 2, 2, 3, 3, 4]; // 1 and 2 are duplicates, don't increment

        for (i, &event_id) in event_ids.iter().enumerate() {
            let tx_hash = B256::repeat_byte((event_id * 10) as u8);
            let event = create_transaction_event(event_id, tx_hash, 1, 1);
            tx.send(event).await.expect("failed to send event");

            let ack = tokio::time::timeout(Duration::from_secs(5), response_stream.next())
                .await
                .expect("timeout waiting for ACK")
                .expect("stream ended")
                .expect("ACK error");

            assert!(ack.success, "event should succeed");
            assert_eq!(ack.event_id, event_id);
            assert_eq!(
                ack.events_processed, expected_processed[i],
                "events_processed mismatch at index {i} for event_id {event_id}"
            );
        }
    }

    /// Create a transaction event with the given parameters for testing.
    fn create_transaction_event(
        event_id: u64,
        tx_hash: B256,
        block_number: u64,
        iteration_id: u64,
    ) -> Event {
        use assertion_executor::primitives::Address;

        let tx_env = pb::TransactionEnv {
            tx_type: 0,
            caller: Address::ZERO.as_slice().to_vec(),
            gas_limit: 21000,
            gas_price: encode_u128_be(1_000_000_000),
            transact_to: Address::ZERO.as_slice().to_vec(),
            value: encode_u256_be(U256::ZERO),
            data: vec![],
            nonce: 0,
            chain_id: Some(1),
            access_list: vec![],
            gas_priority_fee: None,
            blob_hashes: vec![],
            max_fee_per_blob_gas: vec![],
            authorization_list: vec![],
        };

        let tx_execution_id = TxExecutionId {
            block_number: U256::from(block_number).to_be_bytes::<32>().to_vec(),
            iteration_id,
            tx_hash: encode_b256(tx_hash),
            index: 0,
        };

        let transaction = pb::Transaction {
            tx_env: Some(tx_env),
            tx_execution_id: Some(tx_execution_id),
            prev_tx_hash: None,
        };

        Event {
            event_id,
            event: Some(EventVariant::Transaction(transaction)),
        }
    }
}
